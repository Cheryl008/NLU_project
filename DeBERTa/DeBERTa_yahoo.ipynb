{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Good question.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>for religious or philosophical matter yes.  no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>My stomach growled so loud once in Church that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>The same reasons women do.  \\n\\nthe \"game\"...i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>That is my hope.  Unless we examine the mistak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   categories                                               text\n",
       "0           0                                     Good question.\n",
       "1           0  for religious or philosophical matter yes.  no...\n",
       "2           0  My stomach growled so loud once in Church that...\n",
       "3           0  The same reasons women do.  \\n\\nthe \"game\"...i...\n",
       "4           0  That is my hope.  Unless we examine the mistak..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import DebertaTokenizer, DebertaForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from torch.utils.data import Dataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "train_data=pd.read_csv(\"yahoo_train.csv\",header=0,names=['categories', 'text'])\n",
    "test_data=pd.read_csv(\"yahoo_test.csv\",header=0,names=['categories', 'text'])\n",
    "#train_data['classid'] = train_data['classid'].map({3:0,4:1})\n",
    "#test_data['classid'] = test_data['classid'].map({3:0,4:1})\n",
    "train_data['categories'] = train_data['categories'].map(dict(zip(range(1, 11), range(10))))\n",
    "test_data['categories'] = test_data['categories'].map(dict(zip(range(1, 11), range(10))))\n",
    "train_data['text'] = train_data['text'].values.astype('str')\n",
    "test_data['text'] = test_data['text'].values.astype('str')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(train_data['categories'].unique())\n",
    "print(test_data['categories'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    400\n",
       "1    400\n",
       "2    400\n",
       "3    400\n",
       "4    400\n",
       "5    400\n",
       "6    400\n",
       "7    400\n",
       "8    400\n",
       "9    400\n",
       "Name: categories, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['categories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')\n",
    "#from transformers import RobertaTokenizerFast\n",
    "#tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(dataframe,tokenizer,max_seq_length=64):\n",
    "    inputs = list(dataframe['text'])\n",
    "    encoded = tokenizer(inputs,max_length=max_seq_length,truncation=True,padding=\"max_length\",return_tensors=\"pt\")\n",
    "    return encoded\n",
    "\n",
    "def extract_labels(dataframe):\n",
    "    return list(dataframe['categories'])\n",
    "\n",
    "def model_init():\n",
    "    model = DebertaForSequenceClassification.from_pretrained('microsoft/deberta-base',num_labels=10)\n",
    "    return model\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    labels = eval_pred.label_ids\n",
    "    preds = eval_pred.predictions.argmax(-1)\n",
    "    from sklearn.metrics import accuracy_score, normalized_mutual_info_score, adjusted_rand_score\n",
    "    accurcay = accuracy_score(labels,preds)\n",
    "    NMI = normalized_mutual_info_score(labels,preds)\n",
    "    ARI = adjusted_rand_score(labels,preds)\n",
    "    return {'eval_accuracy':accurcay,'eval_NMI':NMI,'eval_ARI':ARI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_recall_fscore_support,log_loss\n",
    "# accuracy_score([0,1,2,3,0,1,2,3],[0,1,2,3,1,1,1,1])\n",
    "# log_loss([0,1,2,3,0,1,2,3],[0,1,2,3,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_seq_length=64):\n",
    "        self.encoded_data = encode_data(dataframe,tokenizer,max_seq_length)\n",
    "        self.label_list = extract_labels(dataframe)\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.label_list)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        item_i = {}\n",
    "        item_i['input_ids'] = self.encoded_data['input_ids'][i]\n",
    "        item_i['attention_mask'] = self.encoded_data['attention_mask'][i]\n",
    "        item_i['labels'] = self.label_list[i]\n",
    "        \n",
    "        return item_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    1,  8585,    32,   171, 37457,   282, 37457,   282,  8863,   448,\n",
       "         37457,   282,   250,  7742, 37457,   282, 24699, 18611, 37457,   282,\n",
       "          7331, 37457,   282,  2336,  3048, 37457,   282,   574,  2796, 44320,\n",
       "         37457,   282,   565,  3196, 15473,  3813, 37457,   282, 36693,   863,\n",
       "          2068, 10466, 44128,   282,  6850,  5330, 12743, 37457,   282,  3721,\n",
       "         12946, 37457,   282,  2118,   100,  2796, 47701, 37457,   282, 21134,\n",
       "         43896, 26624, 37457,     2]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'labels': 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split train_data into training and val data\n",
    "training_data = train_data.sample(frac=0.8, random_state=8521)\n",
    "val_data = train_data.drop(training_data.index)\n",
    "\n",
    "train_data_deberta = CreateDataset(training_data, tokenizer)\n",
    "val_data_deberta = CreateDataset(val_data, tokenizer)\n",
    "test_data_deberta = CreateDataset(test_data, tokenizer)\n",
    "train_data_deberta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models_yahoo/\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=10, \n",
    "    per_device_eval_batch_size=5,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=100,  #每n步更新一次参数,根据数据量调整\n",
    "    logging_first_step=True,\n",
    "    save_steps=960, #每20步储存一次参数,根据数据量调整,存一次就可以了\n",
    "    evaluation_strategy = \"epoch\", # evaluate at the end of every epoch\n",
    "    logging_dir=\"./logs_yahoo/\",\n",
    "    learning_rate=1e-5, #config\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/deberta-base/resolve/main/config.json from cache at /Users/fengwenxin/.cache/huggingface/transformers/e313266bff73867debdfa78c78a9a4966d5e78281ac4ed7048c178b16a37eba7.fb501413b9cef9cef6babdc543bb4153cbec58d52bce077647efba3e3f14ccf3\n",
      "Model config DebertaConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"c2p\",\n",
      "    \"p2c\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"relative_attention\": true,\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/microsoft/deberta-base/resolve/main/pytorch_model.bin from cache at /Users/fengwenxin/.cache/huggingface/transformers/dde0725208c11536042f6f416c538792d44a2d57d1ae399bbd1bc5867e02c465.0a3ec262cb3d4f634c72ce55f2766bb88771e6499b2512830e2e63bf19dbf97a\n",
      "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(args = training_args,\n",
    "                  train_dataset=train_data_deberta,\n",
    "                  eval_dataset=val_data_deberta,\n",
    "                  tokenizer=tokenizer,\n",
    "                  model_init = model_init,\n",
    "                  compute_metrics = compute_metrics,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from ray.tune.suggest.basic_variant import BasicVariantGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tune_config = {\"learning_rate\": tune.uniform(1e-5, 5e-5)} \n",
    "\n",
    "best_results = trainer.hyperparameter_search(\n",
    "    hp_space = lambda _:tune_config,\n",
    "    backend = 'ray',\n",
    "    compute_objective = lambda metrics: metrics[\"eval_ARI\"],\n",
    "    mode = 'max',\n",
    "    search_alg = BasicVariantGenerator(),\n",
    "    n_trials=3, \n",
    ")\n",
    "\n",
    "print(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/deberta-base/resolve/main/config.json from cache at /Users/fengwenxin/.cache/huggingface/transformers/e313266bff73867debdfa78c78a9a4966d5e78281ac4ed7048c178b16a37eba7.fb501413b9cef9cef6babdc543bb4153cbec58d52bce077647efba3e3f14ccf3\n",
      "Model config DebertaConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"c2p\",\n",
      "    \"p2c\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"relative_attention\": true,\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/microsoft/deberta-base/resolve/main/pytorch_model.bin from cache at /Users/fengwenxin/.cache/huggingface/transformers/dde0725208c11536042f6f416c538792d44a2d57d1ae399bbd1bc5867e02c465.0a3ec262cb3d4f634c72ce55f2766bb88771e6499b2512830e2e63bf19dbf97a\n",
      "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 3200\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 10\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 960\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='960' max='960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [960/960 1:41:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Nmi</th>\n",
       "      <th>Ari</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.439500</td>\n",
       "      <td>1.358159</td>\n",
       "      <td>0.578750</td>\n",
       "      <td>0.384189</td>\n",
       "      <td>0.301444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.191400</td>\n",
       "      <td>1.282262</td>\n",
       "      <td>0.588750</td>\n",
       "      <td>0.388927</td>\n",
       "      <td>0.311402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>1.272746</td>\n",
       "      <td>0.592500</td>\n",
       "      <td>0.391903</td>\n",
       "      <td>0.319266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 5\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 5\n",
      "Saving model checkpoint to ./models_yahoo/checkpoint-960\n",
      "Configuration saved in ./models_yahoo/checkpoint-960/config.json\n",
      "Model weights saved in ./models_yahoo/checkpoint-960/pytorch_model.bin\n",
      "tokenizer config file saved in ./models_yahoo/checkpoint-960/tokenizer_config.json\n",
      "Special tokens file saved in ./models_yahoo/checkpoint-960/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 5\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 02:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.5925,\n",
       " 'eval_NMI': 0.39190288617485936,\n",
       " 'eval_ARI': 0.31926614615283705,\n",
       " 'eval_loss': 1.2727457284927368,\n",
       " 'eval_runtime': 123.566,\n",
       " 'eval_samples_per_second': 6.474,\n",
       " 'eval_steps_per_second': 1.295,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Clustering with Fine-tuned Electra and pre-trained Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'classifier.weight', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_finetune = DebertaForSequenceClassification.from_pretrained(\"./models_yahoo/checkpoint-960\",num_labels=10,output_hidden_states=True)\n",
    "model_pretrain = DebertaForSequenceClassification.from_pretrained(\"microsoft/deberta-base\",num_labels=10,output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tokenizer(\"Hello, my dog is cute\", max_length=64,padding=\"max_length\",return_tensors=\"pt\")\n",
    "# outputs = model(**inputs)\n",
    "# #get the text representation from the last hidden layer\n",
    "# length = np.array(inputs['attention_mask'][0]).sum()\n",
    "# encoding = outputs.hidden_states[-1][0].detach().numpy()[:length,:]\n",
    "# encoding = encoding.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = test_data['categories']\n",
    "\n",
    "def text_representation(dataframe,model,tokenizer):\n",
    "    representation = []\n",
    "    for i in tqdm(range(len(dataframe))):\n",
    "        text = dataframe.iloc[i]['text']\n",
    "        inputs = tokenizer(text, max_length=64,padding=\"max_length\",return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)\n",
    "        length = np.array(inputs['attention_mask'][0]).sum()\n",
    "        encoding = outputs.hidden_states[-1][0].detach().numpy()[:length,:]\n",
    "        encoding = list(encoding.mean(axis=0))\n",
    "        representation.append(encoding)\n",
    "    return np.array(representation)\n",
    "\n",
    "# pretrain_train = text_representation(train_data,model_pretrain,tokenizer)\n",
    "# pretrain_test = text_representation(test_data,model_pretrain,tokenizer)\n",
    "# finetune_train = text_representation(train_data,model_finetune,tokenizer)\n",
    "# finetune_test = text_representation(test_data,model_finetune,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4000/4000 [30:04<00:00,  2.22it/s]\n"
     ]
    }
   ],
   "source": [
    "pretrain_train = text_representation(train_data,model_pretrain,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [07:02<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "pretrain_test = text_representation(test_data,model_pretrain,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4000/4000 [29:37<00:00,  2.25it/s]\n"
     ]
    }
   ],
   "source": [
    "finetune_train = text_representation(train_data,model_finetune,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [07:06<00:00,  2.35it/s]\n"
     ]
    }
   ],
   "source": [
    "finetune_test = text_representation(test_data,model_finetune,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_metrics(true_label,preds):  \n",
    "    from sklearn.metrics import accuracy_score, normalized_mutual_info_score, adjusted_rand_score\n",
    "    ACC = round(accuracy_score(true_label,preds),3)\n",
    "    if ACC<=1/len(true_label.unique()): #说明聚类的label，和真实的label没对上\n",
    "        keys = list(pd.value_counts(preds).index)\n",
    "        values = list(pd.value_counts(true_label).index)\n",
    "        dic = dict(zip(keys, values))\n",
    "        preds = pd.Series(preds).map(dic)\n",
    "    NMI = round(normalized_mutual_info_score(true_label,preds),3)\n",
    "    ARI = round(adjusted_rand_score(true_label,preds),3)\n",
    "    ACC = round(accuracy_score(true_label,preds),3)\n",
    "    return {'ACC':ACC,'NMI':NMI,'ARI':ARI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Means\n",
    "from sklearn.cluster import KMeans\n",
    "clustering_model = KMeans(n_clusters = 10, \n",
    "                          init = 'k-means++',\n",
    "                          max_iter = 300, n_init = 10,random_state=8521)\n",
    "clustering_model.fit(pretrain_train)\n",
    "pretrain_KMeans = clustering_model.predict(pretrain_test)\n",
    "clustering_model.fit(finetune_train)\n",
    "finetune_KMeans = clustering_model.predict(finetune_test)\n",
    "print('pretrained text representation:',three_metrics(true_label,pretrain_KMeans))\n",
    "print('finetuned text representation:',three_metrics(true_label,finetune_KMeans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FCM\n",
    "from fcmeans import FCM\n",
    "fcm = FCM(n_clusters=10)\n",
    "fcm.fit(np.array(pretrain_train))\n",
    "pretrain_FCM = fcm.predict(pretrain_test)\n",
    "fcm.fit(np.array(finetune_train))\n",
    "finetune_FCM = fcm.predict(finetune_test)\n",
    "print('pretrained text representation:',three_metrics(true_label,pretrain_FCM))\n",
    "print('finetuned text representation:',three_metrics(true_label,finetune_FCM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "pretrain_train2 = scaler.fit_transform(pretrain_train)\n",
    "pretrain_test2 = scaler.fit_transform(pretrain_test)\n",
    "finetune_train2 = scaler.fit_transform(finetune_train)\n",
    "finetune_test2 = scaler.fit_transform(finetune_test)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=10, random_state=456)\n",
    "lda.fit(pretrain_train2)\n",
    "doc_topic_dist_unnormalized = np.matrix(lda.transform(pretrain_test2))\n",
    "doc_topic_dist = doc_topic_dist_unnormalized/doc_topic_dist_unnormalized.sum(axis=1)\n",
    "pretrain_LDA = list(np.array(doc_topic_dist.argmax(axis=1)).T[0])\n",
    "lda.fit(finetune_train2)\n",
    "doc_topic_dist_unnormalized = np.matrix(lda.transform(finetune_test2))\n",
    "doc_topic_dist = doc_topic_dist_unnormalized/doc_topic_dist_unnormalized.sum(axis=1)\n",
    "finetune_LDA = list(np.array(doc_topic_dist.argmax(axis=1)).T[0])\n",
    "print('pretrained text representation:',three_metrics(true_label,pretrain_LDA))\n",
    "print('finetuned text representation:',three_metrics(true_label,finetune_LDA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ElectraForSequenceClassification.from_pretrained(\"google/electra-base-discriminator\", num_labels=4,output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tokenizer(\"Hello, my dog is cute\", max_length=10,padding=\"max_length\",return_tensors=\"pt\")\n",
    "# outputs = model(**inputs)\n",
    "# outputs.logits"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Baseline-YahooNews.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
